{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping com Python\n",
    "\n",
    "## Introdução\n",
    "\n",
    "Iniciaremos explorando o Website: **https://pythonwebscraping.netlify.app**\n",
    "\n",
    "Começamos importando as bibliotecas essenciais para trabalharmos com **Web Scraping**\n",
    "\n",
    "- A Biblioteca [requests](https://requests.readthedocs.io/en/master/) nos permite fazer requisições HTTP de forma a obtermos o conteúdo HTML do Website\n",
    "- A Biblioteca [re](https://docs.python.org/3/library/re.html) nos permite trabalharmos com expressões regulares para que possamos buscar padrões nos textos extraídos do Website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requisição HTTP\n",
    "\n",
    "Começamos executando uma requisição GET para obtermos o conteúdo HTML do Website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'requests.models.Response'>\n"
     ]
    }
   ],
   "source": [
    "r = requests.get('https://pythonwebscraping.netlify.app')\n",
    "print(type(r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O método `get()` nos retorna um objeto 'requests.models.Response', podemos inspecioná-lo para visualizarmos os atributos e métodos que estão disponíveis para trabalharmos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__attrs__', '__bool__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__enter__', '__eq__', '__exit__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__nonzero__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_content', '_content_consumed', '_next', 'apparent_encoding', 'close', 'connection', 'content', 'cookies', 'elapsed', 'encoding', 'headers', 'history', 'is_permanent_redirect', 'is_redirect', 'iter_content', 'iter_lines', 'json', 'links', 'next', 'ok', 'raise_for_status', 'raw', 'reason', 'request', 'status_code', 'text', 'url']\n"
     ]
    }
   ],
   "source": [
    "print(dir(r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos agora verificar o conteúdo HTML que nos é retornado, para isso vamos acessar o atributo `content`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'<!DOCTYPE html>\\n<html>\\n<head>\\n\\t<meta charset=\"UTF-8\">\\n\\t<title>Web Scraping Tutorial com Python</title>\\n\\t<link rel=\"icon\" href=\"https://i.imgur.com/QOVnf5D.png\">\\n\\t<style>\\n\\t.python {\\n\\t\\tcolor: purple;\\n\\t}\\n\\t#titulo {\\n\\t\\ttext-transform: uppercase;\\n\\t}\\n\\ttable {\\n\\t  border-collapse: collapse;\\n\\t}\\n\\n\\ttable, th, td {\\n\\t  border: 1px solid black;\\n\\t  padding: 3px;\\n\\t}\\n\\t</style>\\n</head>\\n<body>\\n\\t<h1>Web Scraping</h1>\\n\\t<h2>Estrutura B\\xc3\\xa1sica HTML</h2>\\n\\t<img src=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/_images/6.1.jpg\">\\n\\t<p>Aprendendo Web Scraping com <a href=\"https://www.python.org/\">Python</a>,\\n\\t<a href=\"https://github.com/psf/requests-html\">Requests-HTML</a>,\\n\\t<a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\">Beautiful Soup</a> e\\n\\t<a href=\"https://scrapy.org/\">Scrapy</a>\\n\\t</p>\\n\\n\\t<p>\\xe2\\x80\\x9cLogic will get you from A to Z; imagination will get you everywhere.\\xe2\\x80\\x9d <b>Albert Einstein</b></p>\\n\\t\\n\\t<h3 id=\\'titulo\\'>Linguagens de Programa\\xc3\\xa7\\xc3\\xa3o</h3>\\n\\t<ul>\\n\\t\\t<li class=\"python\">Python</li>\\n\\t\\t<li>Perl</li>\\n\\t\\t<li>PHP</li>\\n\\t</ul> \\n\\t\\n\\t<h3 id=\\'titulo\\'>Grandes Matem\\xc3\\xa1ticos</h3>\\n\\t<table>\\n\\t\\t<tr>\\n\\t\\t\\t<th>Nome</th>\\n\\t\\t\\t<th>Sobrenome</th>\\n\\t\\t\\t<th>Email</th>\\n\\t\\t</tr>\\n\\t\\t<tr>\\n\\t\\t\\t<td>Alan</td>\\n\\t\\t\\t<td>Turing</td>\\n\\t\\t\\t<td>alan@turing.com</td>\\n\\t\\t</tr>\\n\\t\\t<tr>\\n\\t\\t\\t<td>John</td>\\n\\t\\t\\t<td>von Neumann</td>\\n\\t\\t\\t<td>john@voneumann.com</td>\\n\\t\\t</tr>\\n\\t\\t<tr>\\n\\t\\t\\t<td>Blaise</td>\\n\\t\\t\\t<td>Pascal</td>\\n\\t\\t\\t<td>blaise@pascal.com</td>\\n\\t\\t</tr>\\n\\t</table>\\n</body>\\n</html>\\n'\n"
     ]
    }
   ],
   "source": [
    "print(r.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos também verificar o tipo de codificação do arquivo acessando o atributo `encoding`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'UTF-8'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O atributo `headers` nos traz detalhes sobre os headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Cache-Control': 'public, max-age=0, must-revalidate', 'Content-Type': 'text/html; charset=UTF-8', 'Date': 'Tue, 10 Nov 2020 23:47:14 GMT', 'Etag': '\"17afc31fb1188dd828f61941a34ae8ad-ssl-df\"', 'Strict-Transport-Security': 'max-age=31536000; includeSubDomains; preload', 'Content-Encoding': 'gzip', 'Content-Length': '743', 'Age': '351', 'Connection': 'keep-alive', 'Server': 'Netlify', 'Vary': 'Accept-Encoding', 'X-NF-Request-ID': '6c6e39a3-537f-4934-adaa-9234afd2e07c-12269260'}\n"
     ]
    }
   ],
   "source": [
    "print(r.headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O atributo `status_code` nos permite verificar o código de status retornado, 200 significa que a requisição ocorreu com sucesso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O atributo `url` nos possibilita verificar a url que foi utilizada na requisição"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://pythonwebscraping.netlify.app/'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por fim o atributo `text` nos traz uma string que representa o documento html que desejamos executar o Web Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html>\n",
      "<head>\n",
      "\t<meta charset=\"UTF-8\">\n",
      "\t<title>Web Scraping Tutorial com Python</title>\n",
      "\t<link rel=\"icon\" href=\"https://i.imgur.com/QOVnf5D.png\">\n",
      "\t<style>\n",
      "\t.python {\n",
      "\t\tcolor: purple;\n",
      "\t}\n",
      "\t#titulo {\n",
      "\t\ttext-transform: uppercase;\n",
      "\t}\n",
      "\ttable {\n",
      "\t  border-collapse: collapse;\n",
      "\t}\n",
      "\n",
      "\ttable, th, td {\n",
      "\t  border: 1px solid black;\n",
      "\t  padding: 3px;\n",
      "\t}\n",
      "\t</style>\n",
      "</head>\n",
      "<body>\n",
      "\t<h1>Web Scraping</h1>\n",
      "\t<h2>Estrutura Básica HTML</h2>\n",
      "\t<img src=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/_images/6.1.jpg\">\n",
      "\t<p>Aprendendo Web Scraping com <a href=\"https://www.python.org/\">Python</a>,\n",
      "\t<a href=\"https://github.com/psf/requests-html\">Requests-HTML</a>,\n",
      "\t<a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\">Beautiful Soup</a> e\n",
      "\t<a href=\"https://scrapy.org/\">Scrapy</a>\n",
      "\t</p>\n",
      "\n",
      "\t<p>“Logic will get you from A to Z; imagination will get you everywhere.” <b>Albert Einstein</b></p>\n",
      "\t\n",
      "\t<h3 id='titulo'>Linguagens de Programação</h3>\n",
      "\t<ul>\n",
      "\t\t<li class=\"python\">Python</li>\n",
      "\t\t<li>Perl</li>\n",
      "\t\t<li>PHP</li>\n",
      "\t</ul> \n",
      "\t\n",
      "\t<h3 id='titulo'>Grandes Matemáticos</h3>\n",
      "\t<table>\n",
      "\t\t<tr>\n",
      "\t\t\t<th>Nome</th>\n",
      "\t\t\t<th>Sobrenome</th>\n",
      "\t\t\t<th>Email</th>\n",
      "\t\t</tr>\n",
      "\t\t<tr>\n",
      "\t\t\t<td>Alan</td>\n",
      "\t\t\t<td>Turing</td>\n",
      "\t\t\t<td>alan@turing.com</td>\n",
      "\t\t</tr>\n",
      "\t\t<tr>\n",
      "\t\t\t<td>John</td>\n",
      "\t\t\t<td>von Neumann</td>\n",
      "\t\t\t<td>john@voneumann.com</td>\n",
      "\t\t</tr>\n",
      "\t\t<tr>\n",
      "\t\t\t<td>Blaise</td>\n",
      "\t\t\t<td>Pascal</td>\n",
      "\t\t\t<td>blaise@pascal.com</td>\n",
      "\t\t</tr>\n",
      "\t</table>\n",
      "</body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(r.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos agora armazenar o conteúdo HTML em uma variável para conveniência e uso futuro desses dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = r.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Buscando Dados com Expressões Regulares\n",
    "\n",
    "Usaremos o poder das expressões regulares para extrair dados de nosso Website"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Título da Página"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = re.findall(r\"<title>(.+?)</title>\", html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Web Scraping Tutorial com Python']\n"
     ]
    }
   ],
   "source": [
    "print(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parágrafos da Página"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = re.findall(r\"<p>(.*?)</p>\", html, flags=re.DOTALL) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Aprendendo Web Scraping com <a href=\"https://www.python.org/\">Python</a>,\\n\\t<a href=\"https://github.com/psf/requests-html\">Requests-HTML</a>,\\n\\t<a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\">Beautiful Soup</a> e\\n\\t<a href=\"https://scrapy.org/\">Scrapy</a>\\n\\t', '“Logic will get you from A to Z; imagination will get you everywhere.” <b>Albert Einstein</b>']\n"
     ]
    }
   ],
   "source": [
    "print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Links da Página"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = re.findall(r'href=[\\'\"]?([^\\'\" >]+)', html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://i.imgur.com/QOVnf5D.png',\n",
       " 'https://www.python.org/',\n",
       " 'https://github.com/psf/requests-html',\n",
       " 'https://www.crummy.com/software/BeautifulSoup/bs4/doc/',\n",
       " 'https://scrapy.org/']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Emails da Página"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "emails = re.findall(r'([\\d\\w\\.]+@[\\d\\w\\.\\-]+\\.\\w+)', html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alan@turing.com', 'john@voneumann.com', 'blaise@pascal.com']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
